version: '3.8'

networks:
  iot_network:
    driver: bridge

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.3 # Il est bon de fixer les versions
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - iot_network
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.3.3
    container_name: kafka
    hostname: kafka
    networks:
      - iot_network
    ports:
      # Port pour accès externe (depuis la machine hôte) si nécessaire: localhost:9093 -> kafka_container:9093
      - "9093:9093" 
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: '${KAFKA_ZOOKEEPER_CONNECT:-zookeeper:2181}' # Utilise .env, fallback si non défini
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      # Le producteur (data_generator) se connectera à kafka:9092 (INTERNAL)
      # Un client sur la machine hôte peut se connecter à localhost:9093 (EXTERNAL)
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Pour les images Confluent Platform, ces variables de licence sont souvent nécessaires
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      # Configuration pour la durabilité des transactions (si utilisées plus tard)
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # Permet la création de topics via une variable d'environnement (définie dans .env)
      # Exemple dans .env: KAFKA_CREATE_TOPICS="iot_sensor_data:1:1"
      KAFKA_CREATE_TOPICS: "${KAFKA_CREATE_TOPICS}"
    restart: unless-stopped


  data_generator:
    build:
      context: ./data_generator # Chemin vers le Dockerfile du producteur
      dockerfile: Dockerfile
    container_name: data_generator
    networks:
      - iot_network
    depends_on:
      - kafka # S'assure que Kafka est démarré avant (mais le script gère les attentes)
    # Injecte les variables d'environnement depuis le fichier .env
    # Le script producer.py lira ces variables
    environment:
      KAFKA_BROKERS: '${KAFKA_BROKERS:-kafka:9092}' # Assurez-vous que cela correspond au listener INTERNE de Kafka
      KAFKA_SENSOR_DATA_TOPIC: '${KAFKA_SENSOR_DATA_TOPIC}'
      DATA_GENERATOR_INTERVAL_SECONDS: '${DATA_GENERATOR_INTERVAL_SECONDS}'
    restart: on-failure
    # Optionnel: monter le volume pour développement local pour éviter de reconstruire l'image à chaque changement de code
    # volumes:
    #   - ./data_generator:/app 